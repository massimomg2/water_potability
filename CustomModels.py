# -*- coding: utf-8 -*-
"""train_all_models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Dojm7RYPuF-lhwT_mPRPlMqGlAPshKFg
"""

# -*- coding: utf-8 -*-
"""train_all_models_standardized.ipynb

Refactorizado para una interfaz de modelo estándar.
"""

import numpy as np
import pandas as pd
from dataclasses import dataclass
from abc import ABC, abstractmethod # Importar Abstract Base Class
import joblib # Importar joblib para guardar

# --- Imports de Scikit-learn ---
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import FunctionTransformer, StandardScaler, RobustScaler
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.cluster import KMeans
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve,
    confusion_matrix, classification_report, precision_recall_curve, adjusted_rand_score,
)
from scipy.stats import ks_2samp

# --- Imports de TensorFlow ---
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# --- Imports de Kaggle ---
import kagglehub
from kagglehub import KaggleDatasetAdapter

# -------------------------------------------------------
#  CARGA DE DATOS
# -------------------------------------------------------

# Set the path to the file you'd like to load
file_path = "water_potability.csv"

# Load the latest version
df = kagglehub.load_dataset(
  KaggleDatasetAdapter.PANDAS,
  "adityakadiwal/water-potability",
  file_path,
)

print("Información inicial del DataFrame:")
df.info()

# -------------------------------------------------------
#  TRANSFORMADOR DE RECORTE CUANTÍLICO
# -------------------------------------------------------
class QuantileClipper(BaseEstimator, TransformerMixin):
    def __init__(self, lower_q=0.005, upper_q=0.995):
        self.lower_q = lower_q
        self.upper_q = upper_q
        self.bounds_ = None

    def fit(self, X, y=None):
        # Asegurarse de que X sea un DataFrame para .quantile()
        X_ = pd.DataFrame(X).copy()
        self.bounds_ = {}
        for c in X_.columns:
            lo = X_[c].quantile(self.lower_q)
            hi = X_[c].quantile(self.upper_q)
            self.bounds_[c] = (lo, hi)
        return self

    def transform(self, X):
        # Asegurarse de que X sea un DataFrame para .clip()
        X_ = pd.DataFrame(X).copy()
        # Asignar nombres de columnas si no los tiene, para que coincidan con self.bounds_
        if not hasattr(X_.columns, 'dtype'):
             X_.columns = range(X_.shape[1])

        for c, (lo, hi) in self.bounds_.items():
             # Asegurarse de que la columna exista en X_
             if c in X_.columns:
                X_[c] = X_[c].clip(lower=lo, upper=hi)
        return X_.values


# -------------------------------------------------------
#  CONFIGURACIÓN
# -------------------------------------------------------
@dataclass
class CleanConfig:
    impute_strategy: str = "median"
    clip_lower_q: float = 0.005
    clip_upper_q: float = 0.995
    skew_threshold: float = 1.0
    scaler: str = "standard"
    reduction: bool = False  # si TRUE → aplica KS test


# -------------------------------------------------------
#  CLASE DE PREPROCESAMIENTO INTEGRADA
# -------------------------------------------------------
class CleanPreprocessor:
    def __init__(self, target, config: CleanConfig):
        # No guardamos df, solo la configuración. El df se pasará a fit_transform
        self.target = target
        self.config = config
        self.pipeline = None
        self.feature_names_in_ = None # Columnas numéricas originales
        self.feature_names_out_ = None # Columnas después del pre-CT
        self.selected_features_ = None # Columnas post-KS
        self._log1p_cols = []
        self._pass_cols = []

    def _select_log1p_cols(self, df, cols):
        skew = df[cols].skew(numeric_only=True)
        return skew.index[skew.abs() > self.config.skew_threshold].tolist()

    def _build_pipeline(self):
        num_imputer = SimpleImputer(strategy=self.config.impute_strategy)

        log1p_transform = Pipeline(steps=[
            ("imputer", num_imputer),
            ("clip", QuantileClipper(self.config.clip_lower_q, self.config.clip_upper_q)),
            ("log1p", FunctionTransformer(np.log1p, feature_names_out="one-to-one"))
        ])

        num_passthrough = Pipeline(steps=[
            ("imputer", num_imputer),
            ("clip", QuantileClipper(self.config.clip_lower_q, self.config.clip_upper_q))
        ])

        transformers = []
        if self._log1p_cols:
            transformers.append(("num_log1p", log1p_transform, self._log1p_cols))
        if self._pass_cols:
            transformers.append(("num_plain", num_passthrough, self._pass_cols))

        pre_ct = ColumnTransformer(
            transformers=transformers,
            remainder="drop",
            verbose_feature_names_out=False
        )

        scaler = RobustScaler() if self.config.scaler == "robust" else StandardScaler()

        return Pipeline([
            ("pre_ct", pre_ct),
            ("scaler", scaler)
        ])

    def _apply_ks_reduction(self, X_df, y):
        selected = []
        pos = X_df[y == 1]
        neg = X_df[y == 0]

        for col in X_df.columns:
            stat, p = ks_2samp(pos[col], neg[col], alternative="two-sided")
            if p < 0.05:
                selected.append(col)

        print(f"[Preprocessor] KS-Test seleccionó {len(selected)} de {len(X_df.columns)} columnas.")
        self.selected_features_ = selected
        return X_df[selected]

    def fit_transform(self, df, y=None):
        """Ajusta y transforma el DataFrame de entrada."""
        df = df.copy()

        # Si y no se pasa, asumimos que está en df
        if y is None:
            y = df[self.target].astype(int)
            df_X = df.drop(columns=[self.target])
        else:
            df_X = df.copy()

        # seleccionar columnas numéricas
        num_cols = df_X.select_dtypes(include=[np.number]).columns.tolist()
        self.feature_names_in_ = num_cols

        # columnas log1p
        self._log1p_cols = self._select_log1p_cols(df_X, num_cols)
        self._pass_cols = [c for c in num_cols if c not in self._log1p_cols]

        # construir pipeline
        self.pipeline = self._build_pipeline()

        X = df_X[num_cols]

        # fit-transform
        X_proc_np = self.pipeline.fit_transform(X, y)

        # nombres de columnas post-CT
        self.feature_names_out_ = self._log1p_cols + self._pass_cols
        X_proc = pd.DataFrame(X_proc_np, columns=self.feature_names_out_, index=df.index)

        # Aplicar reducción si corresponde
        if self.config.reduction:
            X_proc = self._apply_ks_reduction(X_proc, y)
        else:
            self.selected_features_ = self.feature_names_out_

        return X_proc[self.selected_features_], y

    def transform(self, df):
        """Transforma un nuevo DataFrame usando el pipeline ajustado."""
        df_X = df.copy()
        if self.target in df_X.columns:
            df_X = df_X.drop(columns=[self.target])

        X = df_X[self.feature_names_in_]

        X_proc_np = self.pipeline.transform(X)
        X_proc = pd.DataFrame(X_proc_np, columns=self.feature_names_out_, index=df_X.index)

        return X_proc[self.selected_features_]

# -------------------------------------------------------
#  PREPROCESAMIENTO INICIAL Y SPLIT
# -------------------------------------------------------

CFG = CleanConfig(
    impute_strategy="median",
    clip_lower_q=0.005,
    clip_upper_q=0.995,
    skew_threshold=1.0,
    scaler="standard",
    reduction=False  # << activar KS test
)

pre = CleanPreprocessor(target="Potability", config=CFG)
X_clean, y_clean = pre.fit_transform(df)

print("Shape de X procesado:", X_clean.shape)

# Partición train/test
X_train, X_test, y_train, y_test = train_test_split(
    X_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean
)

# ======================================================================
#  INTERFAZ DE MODELO ESTANDARIZADA (CLASE BASE)
# ======================================================================

class BaseModel(ABC):
    """Clase base abstracta para estandarizar la interfaz del modelo."""
    def __init__(self):
        self.model_ = None # El estimador/modelo subyacente
        self.metrics = {}
        self.cm = None
        self.roc_fpr = None
        self.roc_tpr = None
        self.feature_names = None
        self.model_package = None

    @abstractmethod
    def fit(self, X, y, feature_names=None):
        """Entrena el modelo con los datos X, y."""
        self.feature_names = feature_names if feature_names is not None else list(range(X.shape[1]))
        pass

    @abstractmethod
    def predict(self, X):
        """Predice etiquetas de clase para X."""
        pass

    @abstractmethod
    def predict_proba(self, X):
        """Predice probabilidades de clase para X."""
        pass

    def evaluate(self, X_test, y_test):
        """Evalúa el modelo en un conjunto de test y guarda las métricas."""
        if self.model_ is None:
            raise RuntimeError("Debe llamar a .fit() antes de .evaluate()")

        print(f"\n[INFO] Evaluando {self.__class__.__name__}...")

        # Usar predict_proba para métricas (más robusto para AUC)
        try:
            y_prob = self.predict_proba(X_test)
            # Asegurarse que sea 1D array para roc_auc_score
            if y_prob.ndim > 1:
                y_prob = y_prob[:, 1]
        except (NotImplementedError, AttributeError) as e:
            print(f"Warning: predict_proba no implementado para {self.__class__.__name__}. Usando predict() (subóptimo para ROC).")
            y_prob = self.predict(X_test) # Fallback

        y_pred = self.predict(X_test)

        # --- Calcular Métricas ---
        # zero_division=0 evita warnings si una clase no tiene predicciones
        self.metrics = {
            "accuracy": accuracy_score(y_test, y_pred),
            "precision": precision_score(y_test, y_pred, zero_division=0),
            "recall": recall_score(y_test, y_pred, zero_division=0),
            "f1": f1_score(y_test, y_pred, zero_division=0),
        }

        # --- Manejar AUC ---
        try:
            self.metrics["roc_auc"] = roc_auc_score(y_test, y_prob)
        except ValueError as e:
            print(f"Warning: No se pudo calcular ROC AUC: {e}")
            self.metrics["roc_auc"] = None

        # --- Curva ROC ---
        if self.metrics["roc_auc"] is not None:
            self.roc_fpr, self.roc_tpr, _ = roc_curve(y_test, y_prob)
        else:
            self.roc_fpr, self.roc_tpr = None, None

        # --- Matriz de Confusión ---
        self.cm = confusion_matrix(y_test, y_pred)

        print(f"\n==== Métricas de Evaluación ({self.__class__.__name__}) ====")
        print(self.metrics)

        return self.metrics

    def build_model_package(self):
        """Construye el diccionario final para serialización."""
        if not self.metrics:
            raise RuntimeError("Debe llamar a .evaluate() antes de .build_model_package()")

        self.model_package = {
            "pipeline": self,  # Guardamos la instancia completa
            "metrics": self.metrics,
            "cm": self.cm,
            "roc_fpr": self.roc_fpr,
            "roc_tpr": self.roc_tpr,
            "feature_names": self.feature_names,
            "saved_from": "train_all_models_standardized.py",
        }
        print(f"\n[OK] Paquete de modelo creado para {self.__class__.__name__}.")
        return self.model_package

# ======================================================================
#  CLASE 1: MLPClassifier
# ======================================================================

class MLPClassifier(BaseModel):
    """MLP con K-Fold Cross Validation, interfaz estandarizada."""

    def __init__(self, input_dim, n_splits=5, epochs=50, batch_size=32, verbose=0):
        super().__init__()
        self.input_dim = input_dim
        self.n_splits = n_splits
        self.epochs = epochs
        self.batch_size = batch_size
        self.verbose = verbose
        self.cv_results_ = {}

    def build_model(self):
        model = Sequential()
        model.add(Dense(32, activation='relu', input_shape=(self.input_dim,)))
        model.add(Dense(16, activation='relu'))
        model.add(Dense(8, activation='relu'))
        model.add(Dense(1, activation='sigmoid'))

        model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        return model

    def fit(self, X, y, feature_names=None):
        """Entrenamiento con KFold y re-entrenamiento final."""
        super().fit(X, y, feature_names) # Esto setea self.feature_names

        X = np.array(X)
        y = np.array(y)

        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=42)

        fold_accuracies = []
        fold_losses = []

        for fold, (train_idx, val_idx) in enumerate(kf.split(X)):
            if self.verbose > 0:
                print(f"\n>>> Fold {fold + 1}/{self.n_splits}")

            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]

            model = self.build_model()
            model.fit(
                X_train, y_train,
                validation_data=(X_val, y_val),
                epochs=self.epochs,
                batch_size=self.batch_size,
                verbose=self.verbose
            )
            val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)
            fold_losses.append(val_loss)
            fold_accuracies.append(val_acc)

        self.cv_results_ = {
            "loss_mean": np.mean(fold_losses),
            "loss_std": np.std(fold_losses),
            "acc_mean": np.mean(fold_accuracies),
            "acc_std": np.std(fold_accuracies)
        }

        if self.verbose > 0:
            print("\n=== CV Results ===")
            print(self.cv_results_)
            print("\nEntrenando modelo final sobre todo el dataset...")

        # Entrenamiento final con todos los datos
        self.model_ = self.build_model()
        self.model_.fit(
            X, y,
            epochs=self.epochs,
            batch_size=self.batch_size,
            verbose=self.verbose
        )
        return self

    def predict_proba(self, X):
        X = np.array(X)
        return self.model_.predict(X).flatten()

    def predict(self, X, threshold=0.5):
        probs = self.predict_proba(X)
        return (probs >= threshold).astype(int)

    # evaluate() y build_model_package() se heredan de BaseModel


# ======================================================================
#  CLASE 2: DecisionTreeSolver
# ======================================================================

class DecisionTreeSolver(BaseModel):
    """Decision Tree con GridSearchCV, interfaz estandarizada."""

    def __init__(self, param_grid=None, cv=5):
        super().__init__()
        if param_grid is None:
            param_grid = {
                'max_depth': [3, 5, 7, 10, None],
                'min_samples_split': [5, 10],
                'criterion': ['gini']
            }
        self.param_grid = param_grid
        self.cv = cv
        self.grid_search_ = None

    def fit(self, X, y, feature_names=None):
        """Ajusta el GridSearchCV."""
        super().fit(X, y, feature_names)

        grid = GridSearchCV(
            estimator=DecisionTreeClassifier(random_state=42),
            param_grid=self.param_grid,
            cv=self.cv,
            scoring='accuracy',
            n_jobs=-1,
            verbose=0
        )
        grid.fit(X, y)

        self.model_ = grid.best_estimator_
        self.grid_search_ = grid

        print(f"\n[INFO] Mejores params (DecisionTree): {grid.best_params_}")
        print(f"[INFO] Mejor accuracy CV (DecisionTree): {grid.best_score_:.4f}")

        return self

    def predict(self, X):
        return self.model_.predict(X)

    def predict_proba(self, X):
        return self.model_.predict_proba(X) # Devuelve [n_samples, n_classes]

    # evaluate() y build_model_package() se heredan de BaseModel
    # Sobrescribimos evaluate para añadir métricas del grid
    def evaluate(self, X_test, y_test):
        super().evaluate(X_test, y_test)

        self.metrics["best_cv_params"] = self.grid_search_.best_params_
        self.metrics["best_cv_score"] = self.grid_search_.best_score_
        return self.metrics


# ======================================================================
#  CLASE 3: KMeansSolver
# ======================================================================

class KMeansSolver(BaseModel):
    """KMeans como clasificador (con mapping), interfaz estandarizada."""

    def __init__(self):
        super().__init__()
        self.mapping_ = None
        # self.model_ será la instancia de KMeans

    def fit(self, X, y, feature_names=None):
        """Entrena KMeans y crea el mapping a clases."""
        super().fit(X, y, feature_names)

        self.model_ = KMeans(n_clusters=2, random_state=42, n_init="auto")
        labels = self.model_.fit_predict(X)

        # ===== Mapping cluster → clase =====
        df_tmp = pd.DataFrame({"cluster": labels, "target": y})
        mapping = {}
        for c in [0, 1]:
            counts = df_tmp[df_tmp.cluster == c]["target"].value_counts()
            # Asignar el target más común a ese cluster
            mapping[c] = counts.idxmax() if not counts.empty else 0
        self.mapping_ = mapping

        print(f"\n[INFO] Mapping (KMeans): {self.mapping_}")

        return self

    def predict(self, X):
        if self.model_ is None:
            raise RuntimeError("Debe llamar a .fit() antes de .predict()")

        labels = self.model_.predict(X)
        return np.array([self.mapping_[c] for c in labels])

    def predict_proba(self, X):
        """Genera una pseudo-probabilidad basada en la distancia."""
        if self.model_ is None:
            raise RuntimeError("Debe llamar a .fit() antes de .predict_proba()")

        distances = self.model_.transform(X) # Distancia a cada centroide [c0, c1]

        # Invertir y normalizar distancias para obtener "probabilidades"
        # 1 / (d + eps)
        inv_dist = 1.0 / (distances + 1e-6)
        probs_by_cluster = inv_dist / inv_dist.sum(axis=1, keepdims=True)

        # Mapear las probabilidades del cluster a la clase
        # Si mapping_ es {0: 1, 1: 0}
        # probs_clase_0 = probs_by_cluster[:, 1]
        # probs_clase_1 = probs_by_cluster[:, 0]

        # Crear un array de salida [n_samples, 2] para las clases 0 y 1
        probs_by_class = np.zeros_like(probs_by_cluster)

        # Asignar la probabilidad del cluster K a la columna de la clase C
        # según el mapping_
        for cluster_idx, class_label in self.mapping_.items():
            probs_by_class[:, class_label] = probs_by_cluster[:, cluster_idx]

        return probs_by_class # Devuelve [n_samples, n_classes]


    def evaluate(self, X_test, y_test):
        """Sobrescribe la evaluación base para añadir ARI."""
        # Llama a la evaluación base (acc, prec, recall, f1, roc, cm)
        super().evaluate(X_test, y_test)

        # Añadir métricas específicas de clustering (ARI)
        cluster_labels = self.model_.predict(X_test)
        ari = adjusted_rand_score(y_test, cluster_labels)
        self.metrics['ARI'] = ari

        print(f"Métrica adicional (KMeans) - ARI: {ari:.4f}")
        return self.metrics

# ======================================================================
#  CLASE 4: RFClassifier
# ======================================================================

@dataclass
class RFConfig:
    cv: int = 5
    use_smote: bool = False
    random_state: int = 42
    param_grid: dict = None

class RFClassifier(BaseModel):
    """Random Forest con GridSearchCV, interfaz estandarizada."""

    def __init__(self, config: RFConfig):
        super().__init__()
        self.config = config
        self.grid_search_ = None

        # Grilla default
        if self.config.param_grid is None:
            self.config.param_grid = {
                "n_estimators": [200],
                "max_depth": [5, 8],
                "min_samples_split": [2, 3, 4],
                "min_samples_leaf": [2, 3, 4],
                "max_features": ["sqrt"],
                "bootstrap": [True],
            }

    def fit(self, X, y, feature_names=None):
        """Entrena el RF usando GridSearchCV en los datos de train (X, y)."""
        super().fit(X, y, feature_names)

        print("\n[INFO] Iniciando entrenamiento de Random Forest...\n")

        # ---------- SMOTE o class_weight ----------
        if self.config.use_smote:
            try:
                from imblearn.over_sampling import SMOTE
                print("[INFO] Aplicando SMOTE...")
                sm = SMOTE(random_state=self.config.random_state, k_neighbors=5)
                X_res, y_res = sm.fit_resample(X, y)
                class_weight = None
            except ImportError:
                print("[WARN] imblearn no instalado. Omitiendo SMOTE.")
                X_res, y_res = X, y
                class_weight = "balanced_subsample"
        else:
            print("[INFO] Entrenando sin SMOTE (class_weight='balanced_subsample')")
            X_res, y_res = X, y
            class_weight = "balanced_subsample"

        rf = RandomForestClassifier(
            random_state=self.config.random_state,
            n_jobs=-1,
            class_weight=class_weight,
            oob_score=False
        )

        cv_strategy = StratifiedKFold(
            n_splits=self.config.cv,
            shuffle=True,
            random_state=self.config.random_state
        )

        print("[INFO] Iniciando GridSearchCV (Random Forest)...")
        grid = GridSearchCV(
            estimator=rf,
            param_grid=self.config.param_grid,
            scoring="accuracy",
            cv=cv_strategy,
            n_jobs=-1,
            verbose=1,
        )

        grid.fit(X_res, y_res)
        self.model_ = grid.best_estimator_
        self.grid_search_ = grid

        print("\n[OK] Mejores hiperparámetros (RF) encontrados:")
        print(grid.best_params_)
        print(f"[OK] Mejor accuracy CV (RF): {grid.best_score_:.4f}")

        return self

    def predict(self, X):
        return self.model_.predict(X)

    def predict_proba(self, X):
        return self.model_.predict_proba(X) # Devuelve [n_samples, n_classes]

    # evaluate() y build_model_package() se heredan de BaseModel
    def evaluate(self, X_test, y_test):
        super().evaluate(X_test, y_test)

        self.metrics["best_cv_params"] = self.grid_search_.best_params_
        self.metrics["best_cv_score"] = self.grid_search_.best_score_
        return self.metrics

# ======================================================================
#  CLASE 5: GradientBoostingModel
# ======================================================================

class GradientBoostingModel(BaseModel):
    """Gradient Boosting con GridSearchCV, interfaz estandarizada."""

    def __init__(self, cv: int = 5, random_state: int = 42):
        super().__init__()
        self.cv = cv
        self.random_state = random_state
        self.grid_search_ = None

        self.param_grid = {
            "n_estimators": [200],
            "learning_rate": [0.05, 0.1],
            "max_depth": [3, 4],
            "min_samples_leaf": [2, 3],
            "subsample": [0.8],
        }

    def fit(self, X, y, feature_names=None):
        """Entrena Gradient Boosting usando GridSearchCV."""
        super().fit(X, y, feature_names)

        base_model = GradientBoostingClassifier(
            random_state=self.random_state
        )

        cv_strategy = StratifiedKFold(
            n_splits=self.cv,
            shuffle=True,
            random_state=self.random_state,
        )

        print("[INFO] Iniciando GridSearchCV (Gradient Boosting)...")
        grid = GridSearchCV(
            estimator=base_model,
            param_grid=self.param_grid,
            scoring="accuracy",
            cv=cv_strategy,
            n_jobs=-1,
            verbose=1,
        )

        grid.fit(X, y)

        self.model_ = grid.best_estimator_
        self.grid_search_ = grid

        print("\n[OK] Mejores hiperparámetros (GB) encontrados:")
        print(grid.best_params_)
        print(f"[OK] Mejor accuracy CV (GB): {grid.best_score_:.4f}")

        return self

    def predict(self, X):
        return self.model_.predict(X)

    def predict_proba(self, X):
        return self.model_.predict_proba(X) # Devuelve [n_samples, n_classes]

    # evaluate() y build_model_package() se heredan de BaseModel
    def evaluate(self, X_test, y_test):
        """Sobrescribe para añadir métricas de train (opcional) y CV."""
        super().evaluate(X_test, y_test)

        # Añadir métricas de CV
        self.metrics["best_cv_params"] = self.grid_search_.best_params_
        self.metrics["best_cv_score"] = self.grid_search_.best_score_

        # Opcional: Añadir métricas de train si se desea
        # y_train_pred = self.predict(X_train) # Necesitarías X_train
        # train_acc = accuracy_score(y_train, y_train_pred)
        # self.metrics["train_accuracy"] = train_acc

        return self.metrics

# ======================================================================
#  CLASE 6: LogisticRegressionModel
# ======================================================================
class LogisticRegressionModel(BaseModel):
    """
    Regresión Logística con GridSearchCV, interfaz estandarizada.
    Utiliza StratifiedKFold y busca hiperparámetros.
    """

    def __init__(self, param_grid=None, cv=5, random_state=42):
        super().__init__()
        self.cv = cv
        self.random_state = random_state
        self.grid_search_ = None

        if param_grid is None:
            # Una grilla de búsqueda sensata para Regresión Logística
            self.param_grid = {
                'penalty': ['l1', 'l2'],
                'C': [0.01, 0.1, 1.0, 10.0],
                'solver': ['liblinear'], # liblinear es bueno para L1/L2
                'class_weight': ['balanced', None]
            }
        else:
            self.param_grid = param_grid

    def fit(self, X, y, feature_names=None):
        """Ajusta el GridSearchCV para encontrar la mejor Regresión Logística."""
        # Llama al fit de la superclase para guardar feature_names
        super().fit(X, y, feature_names)

        base_model = LogisticRegression(
            random_state=self.random_state,
            max_iter=1000  # Aumentar iteraciones para asegurar convergencia
        )

        cv_strategy = StratifiedKFold(
            n_splits=self.cv,
            shuffle=True,
            random_state=self.random_state
        )

        print("[INFO] Iniciando GridSearchCV (Logistic Regression)...")
        grid = GridSearchCV(
            estimator=base_model,
            param_grid=self.param_grid,
            scoring='accuracy', # Puedes cambiar a 'roc_auc' si lo prefieres
            cv=cv_strategy,
            n_jobs=-1,
            verbose=1
        )

        grid.fit(X, y)

        # Guardamos el mejor estimador como el modelo principal
        self.model_ = grid.best_estimator_
        self.grid_search_ = grid

        print(f"\n[OK] Mejores hiperparámetros (LR) encontrados:")
        print(grid.best_params_)
        print(f"[OK] Mejor accuracy CV (LR): {grid.best_score_:.4f}")

        return self

    def predict(self, X):
        """Predice etiquetas de clase (0 o 1)."""
        return self.model_.predict(X)

    def predict_proba(self, X):
        """Predice probabilidades de clase [prob_0, prob_1]."""
        return self.model_.predict_proba(X)

    def evaluate(self, X_test, y_test):
        """
        Sobrescribe el método base para añadir las métricas de CV
        a los resultados de la evaluación.
        """
        # Llama a la evaluación estándar (acc, prec, recall, f1, auc, cm, roc)
        super().evaluate(X_test, y_test)

        # Añade las métricas específicas del grid search
        if self.grid_search_:
            self.metrics["best_cv_params"] = self.grid_search_.best_params_
            self.metrics["best_cv_score"] = self.grid_search_.best_score_

        return self.metrics